# 第5章 优化程序性能

编译器具有一定的优化能力，但这种能力是有限的。由于一些限制，编译器只能遵循很保守的优化策略，以保证程序在优化前后拥有相同的逻辑。这意味着程序员必须在代码层面编写编译器易于优化的代码。

在本章中，我们使用每元素的周期数（CPE）作为表示程序性能的度量标准。

我们会使用一个通用方式来评估运算时间，下面先给出一个生成向量、访问向量元素和确定向量长度的基本过程。

```c
#include <stdlib.h>
#include "combine.h"

/* $begin vec */
/* Create vector of specified length */
vec_ptr new_vec(long len)
{
    /* Allocate header structure */
    vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
    data_t *data = NULL;
    if (!result)
        return NULL;  /* Couldn't allocate storage */
    result->len = len;
/* $end vec */
    /* We don't show this in the book */
    result->allocated_len = len;
/* $begin vec */
    /* Allocate array */
    if (len > 0) {
        data = (data_t *)calloc(len, sizeof(data_t));
	if (!data) {
	    free((void *) result);
 	    return NULL; /* Couldn't allocate storage */
	}
    }
    /* data will either be NULL or allocated array */
    result->data = data;
    return result;
}

/* Free storage used by vector */
void free_vec(vec_ptr v) {
    if (v->data)
	free(v->data);
    free(v);
}

/*
 * Retrieve vector element and store at dest.
 * Return 0 (out of bounds) or 1 (successful)
 */
int get_vec_element(vec_ptr v, long index, data_t *dest)
{
    if (index < 0 || index >= v->len)
	return 0;
    *dest = v->data[index];
    return 1;
}

/* Return length of vector */
long vec_length(vec_ptr v)
{
    return v->len;
}
/* $end vec */


/* $begin get_vec_start */
data_t *get_vec_start(vec_ptr v)
{
    return v->data;
}
/* $end get_vec_start */


/*
 * Set vector element.
 * Return 0 (out of bounds) or 1 (successful)
 */
int set_vec_element(vec_ptr v, long index, data_t val)
{
    if (index < 0 || index >= v->len)
	return 0;
    v->data[index] = val;
    return 1;
}


/* Set vector length.  If >= allocated length, will reallocate */
void set_vec_length(vec_ptr v, long newlen)
{
    if (newlen > v->allocated_len) {
	free(v->data);
	v->data = calloc(newlen, sizeof(data_t));
	v->allocated_len = newlen;
    }
    v->len = newlen;
}
```

我们使用一个基于上述向量实现的合并函数来刻画性能，具体合并方式可能是加法或乘法，使用的数据类型有整数和浮点数。  
作为基准，下面给出一个合并函数的朴素实现。

```c
void combine1(vec_ptr v, data_t *dest) {
    long i;
    *dest = IDENT;
    for (i = 0; i < vec_length(v); i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

下面是其在参考机上的 CPE 度量值：

![combine1 的 CPE 度量值](_v_images/20211017105616399_23233.png)

可以看到，在未作任何其它处理，仅开启命令行选项 `-O1` 就能实现基本的优化，显著地提高程序性能。在下面的测试中，均使用 `-O1` 或 `-O2` 来生成和测试程序。


## 我们已知的一些简单的优化方法
在前面若干章的学习中，我们已经了解到了一些优化方法，下面来分别进行测试。

### 消除循环的低效率
将在循环中不会变化的值提前计算出来，或者是要在循环中反复调用但返回值不变的函数提前调用并存储其值。在这里即是每次循环都要判断的 `vec_length(v)`。得到 `combine2`。

```c
void combine2(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    *dest = IDENT;
    for (i = 0; i < length; i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

测量得到的 CPE 值如下。

![combine2 的 CPE 值](_v_images/20211017110103357_22600.png)

这种优化方法被称为*代码移动*，优化编译器通常会尝试着进行代码移动，但它们不能可靠地发现一个函数是否有副作用，因而会保守地假设函数都有副作用。程序员必须手动显示地帮助编译器完成代码移动的工作。


### 减少过程调用。
在 `combine2` 的循环体中，我们每次都调用了 `get_vec_element(v, i, &val);`来获得第 i 位的元素，而若阅读这个函数的代码，我们发现每次获取时都要对边界进行一次判断。考虑到在该向量的实现中，数据都是以数组形式存放的，我们猜想，若能直接按照数组方式访问，能否提高程序的执行效率。这样得到 `combine3`。

```c
void combine3(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    *dest = IDENT;
    for (i = 0; i < length; i++)
        *dest = *dest OP data[i];
}
```

测量得到的 CPE 值如下。

![combine3 的 CPE 值](_v_images/20211017110835077_8419.png)

性能没有显著提升。这是因为，虽然在 `get_vec_element()` 函数中出现了条件分支，但该分支是高度可预测的。在现代处理器中，分支预测逻辑非常善于辨别出有规律的模式和长期的趋势，这使得 `get_vec_element()` 函数中的分支预测带来的错误惩罚几乎可以忽略。反而改成数组形式访问时，循环体中的其它操作成了瓶颈。

### 减少不必要的内存引用
将反复的内存引用提取出来，用临时的变量代替，减少内存寻址的次数。

观察 `combine3` 的汇编代码，我们会发现，累计变量 `dest` 在循环体中反复从内存中取出、计算和再写入，而从逻辑上来看，这一内存读写是完全没必要的。我们引入临时累计变量 `acc`，得到 `combine4`。

```c
void combine4(vec_ptr v, data_t *dest) {
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;
    for (i = 0; i < length; i++)
        acc = acc OP data[i];
    *dest = acc;
}
```

测量得到的 CPE 值如下。

![combine4 的 CPE 值](_v_images/20211017111701170_7276.png)

可以看到，性能有了显著的提升。

## 理解现代处理器
为使程序的性能最大化，现代处理器能够同时对多条指令执行，即指令级并行。同时采用精细的设计使得多条指令并行的同时，程序结果与顺序语义模型一致。  
可以使用两种参数描述程序的性能下界。延迟界限，是关于下一条指令开始之前，这条指令必须结束；吞吐量界限则刻画的是处理及功能单元的原始计算能力。这两个界限是程序性能的终极极限。

### 整体架构与乱序执行
以一个类似于 Intel 处理器的结构为例。现代处理器是超标量的，它可以在每个时钟周期执行多个操作，而且是乱序的。整个设计分为**指令控制单元(ICU)**和**执行单元(EU)**两部分，前者负责从内存中读出指令序列，并生成相应操作；后者负责执行操作。下面是一个简单的乱序处理器的框图。

![乱序处理器](_v_images/20211012225716095_27614.png)

ICU 从指令高速缓存（包含最近访问的指令的高速存储器）读取指令，进行译码，在遇到分支时采取分支预测和投机执行的策略，将指令转化为一组基本操作（微操作，如整数加法，内存数据读写），发送给 EU。EU 把指令分配给功能单元，执行实际的操作。不同的单元被用来执行不同的操作组合，这样设计使能同时执行多个同类型的操作。这些得到的结果并不会直接存储到程序寄存器或内存中，因为分支预测的存在，必须等到分支预测正确与否的结果出来之后才能确定，若分支正确，则相关修改会被记录，否则就会被丢弃。  
一个值得关注的是 ICU 中的退役单元，它记录正在进行的处理。译码的指令会进入一个先进先出的队列，当一条指令操作完成且关于它的所有分支预测均正确，这条指令就会被执行并退役，且它所有对程序寄存器的修改都会被实际执行；否则若某个分支点预测错误，该指令就会被清空，有关的计算结果会被丢弃。这一设计保证了处理器能遵循机器级程序的顺序语义。  
在 EU 中有个所有功能单元公用的操作结果区域，这其实就是我们在 `Y86-64` 流水线设计中的转发模块的更精细化实现，它负责在不同执行单元之间交换信息。与之相关的是一个名为**寄存器重命名**的技术，这一技术对每一个要操作的寄存器记录值和时间戳，使得不同指令的寄存器都能得到唯一标识，以便后续转发时能准确寻址。

### 功能单元的性能
通常用以下三种数值来刻画运算的性能：延迟（完成运算所需要的总时间），发射时间（两个连续的同类型运算之间所需的最小时钟周期数）和容量（能执行该运算的功能单元数量），下表是参考机（Intel Core i7 Haswell）的性能。

![参考机运算性能](_v_images/20211017102148268_26744.png)

从表中可以得到以下一些结论：

1. 从整数运算到浮点运算，延迟均是增加的。
2. 加法和乘法运算的发射时间都是 1，这是用流水线方式实现的，如一个典型的浮点加法器可能包括三个阶段（处理指数，将小数相加，对结果舍入）。发射时间为 1 的功能单元也被称为*完全流水线化的*。
3. 除法不是完全流水线化的，并且其延迟和发射的时间是以范围的形式给出，这是因为某些除数与被除数的组合与其它的相比需要更多的步骤。

也可以用**最大吞吐量**来表达发射时间，其定义为发射时间的倒数。对于一个容量为 $C$，发射时间为 $I$ 的操作来说，处理器可能获得的吞吐量为 $\frac{C}{I}$。  
综合延迟、发射时间和容量的影响，我们可以给出每个运算的 CPE 值的两个基本界限来描述。

![CPE](_v_images/20211017103019760_16010.png)

### 处理器操作的抽象模型与关键路径
为更好地分析机器级的程序性能，我们将程序数据流化，即通过展示不同操作之间的数据关联，找出指令之间的执行顺序限制。这些限制形成了约束指令时间周期数的下界。  
具体来说，首先画出各个数据流在寄存器之间的流动以及指令的调用情况，去除掉不影响循环执行的寄存器，得到数据流图和数据相关链，再根据指令的执行时间找出关键路径。  
当然，由数据流中关键路径提供的数据只是程序所需周期数的下界，可能仍有其它的因素会限制性能，

这里以 `combine4` 为例，其基本参数计算或测量如下。

![combine4 的基本参数](_v_images/20211017112107963_7920.png)

其循环体部分汇编代码如下：

```x86asm
# data_t = double, OP = *
# acc in %xmm0, data+i in %rdx, data+length in %rax
.L25
    vmulsd (%rdx), %xmm0, %xmm0
    addq $8, %rax
    cmpq %rax, %rdx
    jne .L25
```

转化为图形化表示如下。

![](_v_images/20211017112559087_6269.png)

可以将涉及到的寄存器分为四类：只读（只作为源值，不会被修改，如这里的 `%rax`），只写（是数据传送操作的目的），局部（只在循环内部被修改和使用，在迭代与迭代之间不相关，如这里的条件码寄存器），循环（在循环中，既作为源值，又作为目的，一次迭代中的值会在另一次迭代中用到，如这里的 `%rdx` 和 `%xmm0`）。循环寄存器之间的操作链决定了限制性能的数据相关。  
将图像化表示进一步改进，只留下影响程序执行性能的操作和数据相关，得到更清晰的数据流如下。

![](_v_images/20211017113047670_18238.png)

最后，将若干个迭代连接起来，找出关键路径。在这一示例中，程序有两条数据相关链，分别对应 `mul` 和 `add`，而浮点乘法的延迟是要比加法更大的，故关键路径为乘法所在的数据链。

![](_v_images/20211017113254150_19633.png)
